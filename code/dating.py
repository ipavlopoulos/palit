# -*- coding: utf-8 -*-
"""palit-dating.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zlngAOH143S8sknxD5D0W4UciTB5JZpp
"""

import matplotlib.pyplot as plt
import os
from tqdm.notebook import tqdm
import pandas as pd
import skimage
import random
import numpy as np
from sklearn.model_selection import train_test_split
from matplotlib.pyplot import figure
from sklearn.metrics import *
from skimage import transform
from sklearn.model_selection import GroupShuffleSplit, train_test_split
from regression import * #CNN

pll = pd.read_pickle("pll.csv")
dataset = pll.explode("img")
dataset = dataset[dataset.img.notna()]
print("Lines num:", dataset.shape[0])

w,h = 300,50
img_data = pd.DataFrame(dataset.img.apply(lambda x: x.shape).tolist(), index=dataset.index, columns=["H", "W"])
dataset = dataset[(img_data.W>w)&(img_data.H>h)]
dataset.insert(0, "lid", range(1, dataset.shape[0]+1))

pll_train, pll_test = train_test_split(dataset, test_size=0.1, random_state=2023)
pll_train, pll_val = train_test_split(pll_train, test_size=pll_test.shape[0], random_state=2023)
print(pll_train.shape[0], pll_val.shape[0], pll_test.shape[0])


if __name__ == "__main__":
    device = "cuda" if torch.cuda.is_available() else "cpu"
    net = Net().to(device)
    mse_loss, mae_loss, train_losses, val_losses = train(net,
                                                         DataLoader(ImageDataset(pll_train, transform=augment), batch_size=16, shuffle=True, drop_last=True),
                                                         optimizer=optim.Adam(net.parameters(), lr=1e-5, weight_decay=1e-5),
                                                         criterion=nn.SmoothL1Loss(), #nn.MSELoss(),
                                                         N_EPOCHS=200,
                                                         device=device,
                                                         val_metric=mean_squared_error,
                                                         patience=20,
                                                         val_dataloader=DataLoader(ImageDataset(pll_val, transform=cc_transform), batch_size=16, drop_last=True)
                                                         )

    torch.save(net.state_dict(), "checkpoint.pt")
    print(f"Parameters: {nn.utils.parameters_to_vector(net.parameters()).numel():.1f}")
    net.eval()

    # evaluation on test
    predictions, labels = validate(net, DataLoader(ImageDataset(pll_test, transform=cc_transform), batch_size=1), device="cpu")
    print("Test loss", nn.L1Loss()(torch.Tensor(predictions), torch.Tensor(labels)).numpy())
    pll_test["cnn"] = predictions
    print(f"Predictions from: {pll_test.cnn.min():.2f} to {pll_test.cnn.max():.2f}, Var: {pll_test.cnn.var():.2f}")
    print(f"MAE: {mean_absolute_error(labels, predictions):g}")
    print(f"MSE: {mean_squared_error(labels, predictions):g}")
